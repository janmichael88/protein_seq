{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X2yqJC8V0_gd"
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow==1.14.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vGeb6dQArE3L"
   },
   "source": [
    "## Introduction\n",
    "* For this notebook we will be exploring other stuctures to classify proteins from their sequence\n",
    "* We will explore 4 different ways\n",
    "* The first way, we will try changing some of the architecture using the emebedding and CONV1d\n",
    "* The second way, we ill trying implemeting an LSTM after the embedding layer\n",
    "* The third way, we will try implementing a GRU after the embedding layer\n",
    "* The fourth way, we will try implementing bi bi-diertional LSTMS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "epH4aV2KrOwW"
   },
   "source": [
    "## First Load in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 525
    },
    "colab_type": "code",
    "id": "gd6fgRcFrDjq",
    "outputId": "c0981885-1b89-4295-d6ac-5939307fd072"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will switch to TensorFlow 2.x on the 27th of March, 2020.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now\n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p4YqTvHYrRqD"
   },
   "outputs": [],
   "source": [
    "proteins = pd.read_csv(\"/content/drive/My Drive/UNH Spring/Protein_seq_project/top_15_proteins.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "SDD2QFJKrYac",
    "outputId": "5f543f8c-1d94-4d65-b2fc-a9567a4dd88e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>sequence</th>\n",
       "      <th>classification</th>\n",
       "      <th>num_residues</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67</td>\n",
       "      <td>TYTTRQIGAKNTLEYKVYIEKDGKPVSAFHDIPLYADKENNIFNMV...</td>\n",
       "      <td>HYDROLASE</td>\n",
       "      <td>286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>68</td>\n",
       "      <td>TYTTRQIGAKNTLEYKVYIEKDGKPVSAFHDIPLYADKENNIFNMV...</td>\n",
       "      <td>HYDROLASE</td>\n",
       "      <td>286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>74</td>\n",
       "      <td>MKTAYIAKQRQISFVKSHFSRQLEERLGLIEVQAPILSRVGDGTQD...</td>\n",
       "      <td>LIGASE</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>75</td>\n",
       "      <td>MKTAYIAKQRQISFVKSHFSRQLEERLGLIEVQAPILSRVGDGTQD...</td>\n",
       "      <td>LIGASE</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>76</td>\n",
       "      <td>KESAAAKFERQHMDSGNSPSSSSNYCNLMMCCRKMTQGKCKPVNTF...</td>\n",
       "      <td>HYDROLASE</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  ... num_residues\n",
       "0          67  ...          286\n",
       "1          68  ...          286\n",
       "2          74  ...          330\n",
       "3          75  ...          330\n",
       "4          76  ...          124\n",
       "\n",
       "[5 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proteins.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d-neV8Mxrhq5"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "# Transform labels to one-hot\n",
    "lb = LabelBinarizer()\n",
    "Y = lb.fit_transform(proteins['classification'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "hqZ9przttXxD",
    "outputId": "76ecab6a-4469-4233-dbdf-485f65d7dfdb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['HYDROLASE', 'HYDROLASE/HYDROLASE INHIBITOR', 'IMMUNE SYSTEM',\n",
       "        'ISOMERASE', 'LIGASE', 'LYASE', 'OXIDOREDUCTASE', 'RIBOSOME',\n",
       "        'RIBOSOME/ANTIBIOTIC', 'SIGNALING PROTEIN', 'TRANSCRIPTION',\n",
       "        'TRANSFERASE', 'TRANSPORT PROTEIN', 'VIRAL PROTEIN', 'VIRUS'],\n",
       "       dtype='<U29'), 15)"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb.classes_,len(lb.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "KmbYQn7_uD7S",
    "outputId": "9da862c0-282b-4ab0-a5e6-1361d3ebbc2e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7ZFcPDXnuRC3"
   },
   "source": [
    "### Vectorize the Sequences\n",
    "* This time try adding padding pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pDKb3FlyuHNk"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import text, sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# maximum length of sequence, everything afterwards is discarded!\n",
    "max_length = 512\n",
    "\n",
    "#create and fit tokenizer\n",
    "tokenizer = Tokenizer(char_level=True)\n",
    "tokenizer.fit_on_texts(proteins['sequence'])\n",
    "#represent input data as word rank number sequences\n",
    "X = tokenizer.texts_to_sequences(proteins['sequence'])\n",
    "X = sequence.pad_sequences(X, maxlen=max_length,padding='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "colab_type": "code",
    "id": "_ICYu3vkuVWW",
    "outputId": "4235736f-8f5d-4774-80fd-44ff4b116191"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 1,\n",
       " 'b': 24,\n",
       " 'c': 17,\n",
       " 'd': 11,\n",
       " 'e': 5,\n",
       " 'f': 14,\n",
       " 'g': 2,\n",
       " 'h': 18,\n",
       " 'i': 9,\n",
       " 'k': 7,\n",
       " 'l': 3,\n",
       " 'm': 19,\n",
       " 'n': 13,\n",
       " 'o': 25,\n",
       " 'p': 12,\n",
       " 'q': 15,\n",
       " 'r': 10,\n",
       " 's': 6,\n",
       " 't': 8,\n",
       " 'u': 20,\n",
       " 'v': 4,\n",
       " 'w': 21,\n",
       " 'x': 22,\n",
       " 'y': 16,\n",
       " 'z': 23}"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yeEisYT2utJa"
   },
   "source": [
    "### Split our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "d2MSvE98uwRT",
    "outputId": "194d2914-b656-4c70-c81c-1b225e6ced54"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((283101, 512), (283101, 15))"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape,Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vNvbs8ojuv9a"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0MjDko7Wuz8e"
   },
   "outputs": [],
   "source": [
    "#keep X_test and y_test until the end get valids\n",
    "X_test.shape\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N8KmDpDouiE2"
   },
   "source": [
    "## Second Model\n",
    "* This notebook is a continuation from another one because I ran out of memory on my computer\n",
    "* Use and LSTM layer after the embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "id": "1o9aKHopufZ1",
    "outputId": "2ad60976-e6d7-4d78-9b18-b784ad830bb7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 512, 16)           416       \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 20)                2960      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 15)                315       \n",
      "=================================================================\n",
      "Total params: 3,691\n",
      "Trainable params: 3,691\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, MaxPooling1D, Flatten\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "\n",
    "embedding_dim = 16\n",
    "depth  = 20\n",
    "\n",
    "# create the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(tokenizer.word_index)+1, embedding_dim, input_length=max_length))\n",
    "model.add(LSTM(depth))\n",
    "model.add(Dense(15, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "esinLxS_1987",
    "outputId": "52925381-5d99-4b42-adeb-b1e25d2d87f5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'embedding_4/embedding_lookup/Identity:0' shape=(?, 512, 16) dtype=float32>,\n",
       " <tf.Tensor 'embedding_4_input:0' shape=(?, 512) dtype=float32>)"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].output, model.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "UFIWMveyytr0",
    "outputId": "bb2e7ac1-fa22-4ba0-dd90-9a6c196b8f17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 229311 samples, validate on 25479 samples\n",
      "Epoch 1/50\n",
      "229311/229311 [==============================] - 675s 3ms/step - loss: 2.0395 - acc: 0.3361 - val_loss: 1.8569 - val_acc: 0.3861\n",
      "Epoch 2/50\n",
      "229311/229311 [==============================] - 677s 3ms/step - loss: 1.8169 - acc: 0.3988 - val_loss: 1.7074 - val_acc: 0.4263\n",
      "Epoch 3/50\n",
      "229311/229311 [==============================] - 686s 3ms/step - loss: 1.6999 - acc: 0.4314 - val_loss: 1.6545 - val_acc: 0.4445\n",
      "Epoch 4/50\n",
      "229311/229311 [==============================] - 684s 3ms/step - loss: 1.6162 - acc: 0.4604 - val_loss: 1.5779 - val_acc: 0.4716\n",
      "Epoch 5/50\n",
      "229311/229311 [==============================] - 689s 3ms/step - loss: 1.5684 - acc: 0.4792 - val_loss: 1.5461 - val_acc: 0.4879\n",
      "Epoch 6/50\n",
      "229311/229311 [==============================] - 688s 3ms/step - loss: 1.5289 - acc: 0.4907 - val_loss: 1.5244 - val_acc: 0.4950\n",
      "Epoch 7/50\n",
      "229311/229311 [==============================] - 689s 3ms/step - loss: 1.5153 - acc: 0.4952 - val_loss: 1.4891 - val_acc: 0.5041\n",
      "Epoch 8/50\n",
      "229311/229311 [==============================] - 692s 3ms/step - loss: 1.4864 - acc: 0.5060 - val_loss: 1.4718 - val_acc: 0.5139\n",
      "Epoch 9/50\n",
      "229311/229311 [==============================] - 692s 3ms/step - loss: 1.4703 - acc: 0.5147 - val_loss: 1.4495 - val_acc: 0.5225\n",
      "Epoch 10/50\n",
      "229311/229311 [==============================] - 692s 3ms/step - loss: 1.4512 - acc: 0.5228 - val_loss: 1.4678 - val_acc: 0.5159\n",
      "Epoch 11/50\n",
      "229311/229311 [==============================] - 692s 3ms/step - loss: 1.4370 - acc: 0.5279 - val_loss: 1.4199 - val_acc: 0.5339\n",
      "Epoch 12/50\n",
      "229311/229311 [==============================] - 692s 3ms/step - loss: 1.4287 - acc: 0.5328 - val_loss: 1.4078 - val_acc: 0.5400\n",
      "Epoch 13/50\n",
      "229311/229311 [==============================] - 691s 3ms/step - loss: 1.4321 - acc: 0.5329 - val_loss: 1.4162 - val_acc: 0.5371\n",
      "Epoch 14/50\n",
      "229311/229311 [==============================] - 689s 3ms/step - loss: 1.4033 - acc: 0.5436 - val_loss: 1.3955 - val_acc: 0.5425\n",
      "Epoch 15/50\n",
      "229311/229311 [==============================] - 687s 3ms/step - loss: 1.4029 - acc: 0.5446 - val_loss: 1.3884 - val_acc: 0.5455\n",
      "Epoch 16/50\n",
      "229311/229311 [==============================] - 689s 3ms/step - loss: 1.3867 - acc: 0.5490 - val_loss: 1.3683 - val_acc: 0.5543\n",
      "Epoch 17/50\n",
      "229311/229311 [==============================] - 692s 3ms/step - loss: 1.3764 - acc: 0.5527 - val_loss: 1.3753 - val_acc: 0.5528\n",
      "Epoch 18/50\n",
      "229311/229311 [==============================] - 691s 3ms/step - loss: 1.3702 - acc: 0.5542 - val_loss: 1.3664 - val_acc: 0.5587\n",
      "Epoch 19/50\n",
      "229311/229311 [==============================] - 688s 3ms/step - loss: 1.3643 - acc: 0.5578 - val_loss: 1.3378 - val_acc: 0.5668\n",
      "Epoch 20/50\n",
      "229311/229311 [==============================] - 689s 3ms/step - loss: 1.3541 - acc: 0.5619 - val_loss: 1.3411 - val_acc: 0.5653\n",
      "Epoch 21/50\n",
      "229311/229311 [==============================] - 693s 3ms/step - loss: 1.3543 - acc: 0.5637 - val_loss: 1.3342 - val_acc: 0.5676\n",
      "Epoch 22/50\n",
      "229311/229311 [==============================] - 694s 3ms/step - loss: 1.3482 - acc: 0.5667 - val_loss: 1.3307 - val_acc: 0.5696\n",
      "Epoch 23/50\n",
      "229311/229311 [==============================] - 696s 3ms/step - loss: 1.3375 - acc: 0.5706 - val_loss: 1.3239 - val_acc: 0.5740\n",
      "Epoch 24/50\n",
      "229311/229311 [==============================] - 690s 3ms/step - loss: 1.3290 - acc: 0.5722 - val_loss: 1.3801 - val_acc: 0.5527\n",
      "Epoch 25/50\n",
      "229311/229311 [==============================] - 680s 3ms/step - loss: 1.3214 - acc: 0.5757 - val_loss: 1.3033 - val_acc: 0.5827\n",
      "Epoch 26/50\n",
      "229311/229311 [==============================] - 683s 3ms/step - loss: 1.3188 - acc: 0.5772 - val_loss: 1.3178 - val_acc: 0.5740\n",
      "Epoch 27/50\n",
      "229311/229311 [==============================] - 686s 3ms/step - loss: 1.3344 - acc: 0.5725 - val_loss: 1.3668 - val_acc: 0.5702\n",
      "Epoch 28/50\n",
      "229311/229311 [==============================] - 683s 3ms/step - loss: 1.3160 - acc: 0.5788 - val_loss: 1.3061 - val_acc: 0.5801\n",
      "Epoch 29/50\n",
      "229311/229311 [==============================] - 693s 3ms/step - loss: 1.3280 - acc: 0.5762 - val_loss: 1.3068 - val_acc: 0.5784\n",
      "Epoch 30/50\n",
      "229311/229311 [==============================] - 699s 3ms/step - loss: 1.3620 - acc: 0.5659 - val_loss: 1.3310 - val_acc: 0.5736\n",
      "Epoch 31/50\n",
      "229311/229311 [==============================] - 694s 3ms/step - loss: 1.3056 - acc: 0.5823 - val_loss: 1.3079 - val_acc: 0.5827\n",
      "Epoch 32/50\n",
      "229311/229311 [==============================] - 693s 3ms/step - loss: 1.3072 - acc: 0.5820 - val_loss: 1.2925 - val_acc: 0.5870\n",
      "Epoch 33/50\n",
      "131200/229311 [================>.............] - ETA: 4:36 - loss: 1.3401 - acc: 0.5714"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, \n",
    "          validation_data=(X_valid, y_valid), \n",
    "          epochs=50, \n",
    "          batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BOx69gLJzAqw"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Protein_Classification_Trying_Other_Models_Models_2_to_4.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
